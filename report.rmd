---
title: "Written Report"
output: 
  html_document:
    toc: true
    toc_float: true
    code_folding: hide
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE,
  warning = FALSE,
  message = FALSE,
  dev.args = list(bg = "transparent"),
  comment = NA
  )
```

```{r}
library(tidyverse)
library(knitr)
library(lubridate)
library(ggcorrplot)
library(plotly)
library(scales)
library(randomForest)
library(caTools)

steam_theme <- theme_classic() + 
  theme(
    panel.background = element_rect(fill = "transparent", color = NA), 
    plot.background = element_rect(fill = "transparent", color = NA),
    legend.background = element_rect(fill = "transparent", color = NA),
    legend.box.background = element_rect(fill = "transparent", color = NA),
    text = element_text(color = "#66c0f4")
    )

theme_set(steam_theme)
```

# Motivation

Video game industry is a highly competitive market where thousands of new products are released annually. For developers, understanding the specific factors that drive player engagement is important when allocating their resources. For players facing an overwhelming number of choices, identifying games that align with their interests is a challenge. This project is motivated by both the need to bridge this gap and our enthusiasm towards gaming: by analyzing real-world data from [Steam](https://en.wikipedia.org/wiki/Steam_(service)), we aim to build a predictive model that can estimate a game's popularity based on current metadata.

# Related Work

Our work is inspired by the recent kick-off of [TGA](https://thegameawards.com/nominees/game-of-the-year): An once-a-year celebration of game developers and players, simply consider it as the Oscar of gaming industry.

# Initial Questions

Our major questions is: **What are the primary drivers of game popularity on Steam?**

As we explored the dataset, this question evolved into some hypotheses:

- "Does a higher price point correlate with higher quality and thus more players?" 
- "Are buyers necessarily players?"

- "Are games with more positive reviews being played more?"

- "Which types of games are being played the most? Action or RPG?"

- "Does a DLCs attract more players into playing?"

# Data

## Data Source

The dataset used for this project is made possible by [FronkonGames](https://fronkongames.github.io/) and is sourced at [huggingface.co](https://huggingface.co/datasets/FronkonGames/steam-games-dataset).

## Scraping

The author provides an official python script to scrape this dataset, it can be viewed [here](data/scrapping.py). Additionally, we did some sampling 
from local. The chunk below converted a dataframe of 110000 rows to 10629 rows to pass Github's file uploading size. It is not meant to be ran.
```{r}
# df = read_csv("steam_games.csv") |>
#   filter(!is.na(average_playtime),
#          !is.na(peak_ccu),
#          !is.na(median_playtime))

# write_csv(df, "steam_games.csv")
```

## Cleaning

During the cleaning process, our pipeline aims to:

- Make sure variable names are consistent across columns

- Select only the unique identifier and necessary variables for our popularity analysis

- Make sure continuous variables are numeric

- Make sure `release_date` is in date format for later manipulations

- Convert the `estimated_owners` from a range to a numeric value by taking the midpoint

- Create a `primary_genre` variable. This will be the first string in list `genres`

- Make sure no zeros or NAs are present in `average_playtime`, `median_playtime` and `peak_ccu` as they are meaningless in these columns

```{r}
steam_df = read_csv("data/steam_games.csv") |>
  janitor::clean_names() |>
  select(
    app_id, name, release_date, price,
    estimated_owners, peak_ccu, average_playtime, median_playtime,
    dlc_count, developers, genres, positive, negative
  ) |>
  mutate(
    price = as.numeric(price),
    dlc_count = as.numeric(dlc_count),
    positive = as.numeric(positive),
    negative = as.numeric(negative),
    release_date = mdy(release_date),
    primary_genre = as.factor(sub(",.*", "", genres)), 
  ) |>
  mutate(estimated_owners = str_extract(estimated_owners, "\\d+"),
         estimated_owners = as.numeric(estimated_owners)) |>
  filter(
    average_playtime > 0,
    median_playtime > 0,
    peak_ccu > 0
  )
```

## Key Variables

**app_id**: Unique identifier of each game

**name**: Game name on Steam

**release_date**: Official releasing time in yyyy-mm-dd

**price**: Price in USD

**estimated_owners**: Rough estimate of owners

**peak_ccu**: Peak number of online concurrent users

**average_playtime, median_playtime**: Playtime since March 2009, in minutes

**dlc_count**: Number of DLCs (expansion or extra chapters sold separately from the game)

**developers**: Creator of the game

**genres**: Theme of the game

**positive, negative**: Number of positive / negative reviews by user on Steam

# Exploratory Data Analysis

In our exploratory data analysis, we want to understand what factors drive game popularity on Steam. We begin by exploring the distribution of the key outcome variable: `peak_ccu` (peak_concurrent users) along with their relationships to potential predictors such as playtime, price, release year, estimated owners, and genre/category information. In details, we are aiming to: 

- Identify general patterns in popularity 

- Assess data quality and transformations needed for modeling

- Detect early signals of which features might influence engagement

## Distribution of Peak Concurrent Users

```{r}
pccu_distribution = steam_df |>
  ggplot(aes(x = peak_ccu)) +
  geom_histogram(bins = 50, fill = "#66c0f4") +
  scale_x_continuous(trans = "log10") +
  labs(
    title = "Distribution of Peak Concurrent Users (Log Scale)",
    x = "Peak CCU"
  )

ggplotly(pccu_distribution)
```

Note that peak_ccu is heavily tailed. A tiny handful of games (like Counter-Strike 2, Dota 2, PUBG) have millions of CCU and owners, while the vast majority of games have very few owners and almost zero peak CCU. Applying log scales here allow us to compare games based on multiplicative differences rather than additive ones. For developers, the jump from 1,000 owners to 10,000 owners is just as significant as the jump from 100,000 to 1,000,000.

## Estimated Owners vs Popularity 

Owners represent the overall reach of a game while peak_ccu reflects active use. Games with high owner counts but low CCU may indicate weak long-term engagement. The plot below visualizes the correlation between estimated owners and peak CCU.

```{r}
eo_boxplot = steam_df |>
  ggplot(aes(x = factor(estimated_owners), y = peak_ccu)) +
  geom_boxplot(fill = "#66c0f4", alpha = 0.6, color = "#66c0f4") +
  scale_y_continuous(trans = "log10") +
  labs(
    title = "Distribution of Peak CCU by Owner Tier",
    x = "Estimated Owners Tier",
    y = "Peak CCU (Log Scale)"
  )

ggplotly(eo_boxplot)
```

In the lower tiers (left side), the whiskers are long, and outliers are everywhere. Performance is unpredictable. In the highest tiers ($1e+07$), the boxes are tighter. Namely, If you have 10 million owners, your CCU is predictably massive. There are very few "dead" games with 10 million owners.

## User Satisfaction vs Popularity

Reviews reflect user satisfaction. If higher satisfaction correlates with higher playtime, review sentiment becomes a strong candidate predictor. Here, we define satisfaction with Review Ratio:
\[
RR = \frac{Positive}{Positive + Negative} 
\]

```{r}
rr_trend = steam_df |>
  mutate(
    total_reviews = positive + negative,
    review_ratio = positive / total_reviews
  ) |>
  filter(total_reviews > 50) |>
  ggplot(aes(x = review_ratio, y = peak_ccu)) +
  geom_point(alpha = 0.2, size = 0.8, color = "#66c0f4") +
  geom_smooth(method = "gam", color = "#e6e9f0", se = FALSE) +
  scale_y_log10(
    labels = label_number(accuracy = 1, big.mark = ","),
    breaks = trans_breaks("log10", function(x) 10^x)
  ) +
  scale_x_continuous(labels = scales::percent) +
  labs(
    title = "Review Ratio vs Peak CCU",
    x = "Positive Review Ratio",
    y = "Peak CCU"
  )

ggplotly(rr_trend)
```

The white trend line stays relatively flat for a long time and then curves upward sharply once the Review Ratio exceeds roughly 75%.
This implies that moving from a "Bad" game (25%) to a "Mediocre" game (50%) yields very little gain in popularity. However, moving from "Good" (75%) to "Excellent" (95%+) yields an significant increase in peak players.

## Popularity by Genre

Genres encapsulate game design choices, and identifying which genres drive deeper engagement is important for game developers. Below we list the top 15 most popular genres on Steam.

```{r}
genres_trend_plot = steam_df |>
  separate_rows(genres, sep = ",\\s*") |>
  filter(!genres %in% c("Free to Play", "Early Access")) |>
  group_by(genres) |>
  summarize(
    total_ccu = sum(peak_ccu, na.rm = TRUE),
    n_games = n()
  ) |>
  arrange(desc(total_ccu)) |>
  slice_head(n = 15) |>
  ggplot(aes(x = reorder(genres, total_ccu), 
             y = total_ccu,
             text = paste("Genre:", genres, 
                          "<br>Total CCU:", scales::comma(total_ccu),
                          "<br>Number of Games:", n_games))) +
  geom_col(fill = "#66c0f4") +
  coord_flip() +
  scale_y_continuous(labels = scales::comma) +
  labs(
    title = "Top Genres by Total Peak CCU",
    x = "Genre",
    y = "Total Peak CCU"
  )

ggplotly(genres_trend_plot, tooltip = "text")
```

The plot above gives very intuitive results, and the 5 most popular genres are: Action, Adventure, RPG(Role Play), Indie, and Simulation. Clicking on each bar will show the number of games in that genre. For developers, a bigger market (more CCU) is almost certainly filled with more competitors. RPG is a very special genre with 6,329,228 peak CCU but only 2590 games, as the cost of making a RPG is usually expensive.

## Correlation

Lastly, we use a correlation graph to check for potential predictors for our model.

```{r}
correlation_matrix = steam_df |>
  mutate(
    release_date = as.numeric(release_date),
    total_reviews = positive + negative,
    review_ratio = ifelse(total_reviews > 0, positive / total_reviews, 0),
    log_peak_ccu = log1p(peak_ccu),
    log_estimated_owners = log1p(estimated_owners),
    log_price = log1p(price),
    log_average_playtime = log1p(average_playtime)
  ) |>
  select(log_price, log_estimated_owners, release_date,
         log_peak_ccu, log_average_playtime, median_playtime,
         dlc_count, review_ratio) |>
  cor(use = "complete.obs") |>
  ggcorrplot(
    lab = FALSE, 
    hc.order = TRUE, 
    ggtheme = steam_theme,
    outline.color = "white",
    colors = c("#6D9EC1", "white", "#E46726"))

ggplotly(correlation_matrix)
```

From the correlation matrix and other plots, we find `peak_ccu` and most variables are weak linearly. Therefore, for our additional analysis, instead of performing a Linear Regression, we use a Random Forest regressor to unveil relationships and interactions.

# Random Forest

## Modeling Strategy

This additional analysis aims to predict the maximum concurrent player count (`peak_ccu`) for Steam games based on current metadata. By modeling the relationship between game attributes—such as price, genre, and release timing—and player traffic, we can identify the key drivers of a game's commercial performance.

We selected a Random Forest as our modeling algorithm. This decision was made by the some characteristics of the Steam dataset observed during [Exploratory Data Analysis](eda.html):

- **Weak Linearity**: Our correlation matrix revealed that relationships between variables are barely linear. Random Forest captures complex, non-linear interactions without requiring manual equation fitting.

- **Robustness to Outliers**: Steam data has a skewed distribution, where a few massive hits coexist with thousands of small games. Random Forest averages the results of multiple decision trees, preventing these extreme outliers from messing up the entire model.

## Data Preparation

To address the extreme skewness of the data, we perform a log1p transformation ($y = \ln(x + 1)$) to `peak_ccu` and continuous features. This transformation, as we previously mentioned, allows the model to learn magnitudes.

```{r}
model_data = steam_df |>
  mutate(
    log_peak_ccu = log1p(peak_ccu),
    log_price = log1p(price),
    release_date = as.numeric(release_date),
    total_reviews = positive + negative,
    review_ratio = ifelse(total_reviews > 0, positive / total_reviews, 0),
    log_estimated_owners = log1p(estimated_owners),
    log_average_playtime = log1p(average_playtime)
  ) |>
  select(log_peak_ccu, log_price, log_estimated_owners, log_average_playtime, dlc_count, primary_genre, release_date, review_ratio) |>
  na.omit()
```

## Training Regressoor

We first set a seed to make sure our work is reproducible. The dataset was then split into training (80% of original data) and testing (20% of original data) sets. Finally, we start training our Random Forest regressor with 500 decision trees and save this model as `rf_model`. The details of `rf_model` is given below.
```{r}
set.seed(8105)

split = sample.split(model_data$log_peak_ccu, SplitRatio = 0.8)
train_set = subset(model_data, split == TRUE)
test_set = subset(model_data, split == FALSE)

rf_model = randomForest(log_peak_ccu ~ ., 
                         data = train_set, 
                         ntree = 500, 
                         importance = TRUE)

print(rf_model)
```

## Evaluation

```{r}
log_predictions = predict(rf_model, newdata = test_set)
real_predictions = expm1(log_predictions)
real_actuals = expm1(test_set$log_peak_ccu)

rmse = sqrt(mean((real_predictions - real_actuals)^2))
print(paste("Root Mean Squared Error (in players):", round(rmse, 4)))

nrmse_mean <- rmse / mean(real_actuals)
print(paste("Normalized RMSE (Mean):", round(nrmse_mean, 4)))
```

We first generate the log-scale predictions. Then we reverse our log transformation with exponential equation to get the RMSE (Root Mean Squared Error) in actual player units. Additionally, we apply normalization to our RMSE to get NRMSE, where:
\[
NRMSE = \frac{RMSE}{Mean}
\]

NRMSE tells us the error percentage relative to the average game. The final model achieved a RMSE of 123 and a Normalized RMSE of 2.6. Considering the large variance of the dataset, our model holds a fairly stable predictive capability.

# Result & Discussion

## Findings
From the Variable Importance Plot of our model below, there are several findings:

```{r}
imp_dat <- as.data.frame(importance(rf_model))
imp_dat$var_name <- rownames(imp_dat)

ggplot(imp_dat, aes(x = IncNodePurity, y = reorder(var_name, IncNodePurity))) +
  geom_point(color = "#66c0f4", size = 3) +
  geom_segment(aes(x = 0, xend = IncNodePurity, y = var_name, yend = var_name),
               color = "#66c0f4") + 
  labs(title = "What drives Peak CCU?",
       x = "Importance (IncNodePurity)",
       y = "Variable Name")
```

- **Fans of Recency (`release_date`)**: The most significant predictor of peak_ccu was the release date. This indicates a strong "recency bias" in the Steam marketplace: people prefer new stuff. Newer games benefit from the "hype cycle" and marketing pushes, while older titles—regardless of quality—tend to see significant player churn. The model successfully learned the lifecycle decay of a typical video game.

- **Buyers are Players (`estimated_owners`)**: The number of estimated owners served as a strong secondary predictor. However, this result may come from the logical constraint that people can only play a game when they own it.

- **The Role of Content (`primary_genre`)**: Surprisingly, primary_genre showed lower predictive power compared to other factors. This result suggests that while genre defines the type of player, it does not strictly dictate the volume of players. This may also reflect a limitation in our feature engineering: by isolating only the primary genre, the model may miss the nuances of multi-genre titles.

## Conclusion

Our model validates that timing and reach (release window and ownership) are statistically more significant predictors of peak traffic than price or broad genre classifications. The fact that these two predictors shows in top is very surprising, as none of the team members expected or proposed such outcome. Future iterations of this study could improve accuracy by incorporating granular tag analysis (e.g., "Co-op", "PvP") to better capture the retention mechanics of specific game loops.
